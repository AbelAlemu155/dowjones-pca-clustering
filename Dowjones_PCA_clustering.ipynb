{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# instantiate the data for the 30 stocks defined by the tickers \n",
    "all_dow_tickers  = ['MMM', 'AXP', 'AMGN','AMZN', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'DIS','GS', 'HD', \n",
    "                    'HON', 'IBM', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE', \n",
    "                    'NVDA','PG','CRM','SHW', 'TRV', 'UNH', 'VZ','V',\n",
    "                    'WMT',]\n",
    "all_dow_tickers.sort()\n",
    "\n",
    "\n",
    "# download all the ticker data using yahoo finance functionality \n",
    "yahoo_finance_data = pd.DataFrame(yf.download(all_dow_tickers, start=\"2023-01-01\", end=\"2023-12-31\"))[\"Adj Close\"]\n",
    "# use the unnormalized returns \n",
    "unnormalized_daily_returns = yahoo_finance_data.reset_index().drop(columns='Date').pct_change()*100\n",
    "\n",
    "# compute the correlation matrix using corr() functionality on the logarithm returns\n",
    "\n",
    "correlation_matrix_stocks = unnormalized_daily_returns.corr()\n",
    "\n",
    "\n",
    "# instantiate a pca object to fit the correlation matrix\n",
    "pca_object = PCA()\n",
    "# fit using the correlation matrix \n",
    "pca_object.fit(correlation_matrix_stocks)\n",
    "\n",
    "\n",
    "# get the loading components/ contributions for the first and second principal components \n",
    "pca1_loadings = pca_object.components_[0]\n",
    "pca2_loadings = pca_object.components_[1]\n",
    "\n",
    "# construct a loading data frame to plot the graph of the weightings of each components \n",
    "\n",
    "loadings_frame = pd.DataFrame({\n",
    "    \"Stocks\": correlation_matrix_stocks.index,\n",
    "    \"PC1\": pca1_loadings,\n",
    "    \"PC2\": pca2_loadings\n",
    "})\n",
    "# visualize the loading components for the first principal component\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.bar(loadings_frame[\"Stocks\"], loadings_frame[\"PC1\"], color='blue', alpha=0.7)\n",
    "plt.title(\"Weights of Stocks in First Principal Component (PC1)\")\n",
    "plt.xlabel(\"All Stocks\")\n",
    "plt.ylabel(\"Weight/Loadings\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# visualize the loading components for the second principal component\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(loadings_frame[\"Stocks\"], loadings_frame[\"PC2\"], color='green', alpha=0.7)\n",
    "plt.title(\"Weights of Stocks in Second Principal Component (PC2)\")\n",
    "plt.xlabel(\"All Stocks\")\n",
    "plt.ylabel(\"Weights/Loadings\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the explained variance ratio from the pca object \n",
    "explained_var_r = pca_object.explained_variance_ratio_\n",
    "\n",
    "# Compute the cumulative variance necessary to compute number of principal components needed to explain 95 percent variance \n",
    "cumulative_var = np.cumsum(explained_var_r)\n",
    "\n",
    "# plot the variance of each principal component\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(range(1, len(explained_var_r) + 1), explained_var_r, alpha=0.8, label=\"Variance of individual PCS\")\n",
    "plt.plot(range(1, len(cumulative_var) + 1), cumulative_var, marker='x', color='blue', label=\"Cumulative Variance\")\n",
    "plt.axhline(y=0.95, color='green', linestyle='--', label=\"95% Threshold\")\n",
    "\n",
    "# show the needed data and labels for the principal components\n",
    "plt.title(\"Variance of each principal component\", fontsize=14)\n",
    "# display the appropriate x label \n",
    "plt.xlabel(\"Principal Components\", fontsize=12)\n",
    "# display the appropriate y label\n",
    "plt.ylabel(\"Explained Variance \", fontsize=12)\n",
    "# use countable values for the x ranges\n",
    "plt.xticks(range(1, len(explained_var_r) + 1))  \n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(axis='y', linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute the number of principal components needed for 95% variance\n",
    "num_components_95 = np.argmax(cumulative_var >= 0.95) + 1\n",
    "print(f\"Number of principal components to explain 95% of the variance: {num_components_95}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pc_scores data frame for visualization purposes\n",
    "pc_scores_data_frame = pd.DataFrame({\n",
    "    \"Stock\": loadings_frame[\"Stocks\"],\n",
    "    \"PC1\": pca1_loadings,\n",
    "    \"PC2\": pca2_loadings\n",
    "}) \n",
    "\n",
    "# plot a scatter plot for the first two scatter plots \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plot the score of the two pc scores \n",
    "plt.scatter(pca1_loadings, pca2_loadings, alpha=0.7, color=\"red\")\n",
    "\n",
    "# insert the appropriate text information\n",
    "for i, stock in enumerate(pc_scores_data_frame[\"Stock\"]):\n",
    "    plt.text(pc_scores_data_frame[\"PC1\"][i], pc_scores_data_frame[\"PC2\"][i], stock, fontsize=9, alpha=0.8)\n",
    "\n",
    "# insert the axis lines for better visualization\n",
    "plt.axhline(0, color=\"grey\", linestyle=\"--\", linewidth=0.7)\n",
    "plt.axvline(0, color=\"grey\", linestyle=\"--\", linewidth=0.7)\n",
    "# insert the appropriate titles\n",
    "plt.title(\"Scatter Plot for the  Two Principal Components\")\n",
    "# insert the appropriate x labels\n",
    "plt.xlabel(\"PC1\")\n",
    "# insert the appropriate y labels \n",
    "plt.ylabel(\"PC2\")\n",
    "plt.tight_layout()\n",
    "# display the plot of the graph\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# compute the mean of all stocks for pc1 and pc2 \n",
    "mean_principal_component1 = pc_scores_data_frame[\"PC1\"].mean()\n",
    "mean_principal_component2 = pc_scores_data_frame[\"PC2\"].mean()\n",
    "\n",
    "# compute the euclidean distance for the pcscores valus \n",
    "pc_scores_data_frame[\"Euclidean_Distance_PC1\"] = np.sqrt((pc_scores_data_frame[\"PC1\"] - mean_principal_component1)**2)\n",
    "pc_scores_data_frame[\"Euclidean_Distance_PC2\"] = np.sqrt((pc_scores_data_frame[\"PC2\"] - mean_principal_component2)**2)\n",
    "\n",
    "#get the 3 farthest stocks using the euclidean distance for each principal components\n",
    "top3_principal_components1 = pc_scores_data_frame.nlargest(3, \"Euclidean_Distance_PC1\")\n",
    "top3_principal_components2 = pc_scores_data_frame.nlargest(3, \"Euclidean_Distance_PC2\")\n",
    "\n",
    "print(\"The first 3 most distant stocks for PC1 are using euclidean distance:\")\n",
    "print(top3_principal_components1[[\"Stock\", \"PC1\", \"Euclidean_Distance_PC1\"]])\n",
    "print(\"\\n The first 3 most distant stocks for PC2 are using euclidean distance:\")\n",
    "print(top3_principal_components2[[\"Stock\", \"PC2\", \"Euclidean_Distance_PC2\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# get the correlation matrix values to determine the pair wise distance dissimilarity\n",
    "corr_values_stocks = correlation_matrix_stocks.values \n",
    "\n",
    "# compute the distance / dissimilarity matrix to d \n",
    "dissimilarity_matrix = np.sqrt(2 * (1 - corr_values_stocks))\n",
    "\n",
    "print(f'the disimilarity matrix is : {dissimilarity_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all stocks names \n",
    "company_map = company_map = {\n",
    "    \"MMM\": \"3M\",\n",
    "    \"AXP\": \"American Express\",\n",
    "    \"AMGN\": \"Amgen\",\n",
    "    \"AMZN\": \"Amazon\",\n",
    "    \"AAPL\": \"Apple\",\n",
    "    \"BA\": \"Boeing\",\n",
    "    \"CAT\": \"Caterpillar\",\n",
    "    \"CVX\": \"Chevron\",\n",
    "    \"CSCO\": \"Cisco Systems\",\n",
    "    \"KO\": \"Coca-Cola\",\n",
    "    \"DIS\": \"Walt Disney Company\",\n",
    "    \"GS\": \"Goldman Sachs\",\n",
    "    \"HD\": \"Home Depot\",\n",
    "    \"HON\": \"Honeywell\",\n",
    "    \"IBM\": \"International Business Machines\",\n",
    "    \"JNJ\": \"Johnson & Johnson\",\n",
    "    \"JPM\": \"JPMorgan Chase\",\n",
    "    \"MCD\": \"McDonald's\",\n",
    "    \"MRK\": \"Merck & Co.\",\n",
    "    \"MSFT\": \"Microsoft\",\n",
    "    \"NKE\": \"Nike\",\n",
    "    \"NVDA\": \"NVIDIA\",\n",
    "    \"PG\": \"Procter & Gamble\",\n",
    "    \"CRM\": \"Salesforce\",\n",
    "    \"SHW\": \"Sherwin-Williams\",\n",
    "    \"TRV\": \"Travelers\",\n",
    "    \"UNH\": \"UnitedHealth Group\",\n",
    "    \"VZ\": \"Verizon Communications\",\n",
    "    \"V\": \"Visa\",\n",
    "    \"WMT\": \"Walmart\"\n",
    "}\n",
    "company_names = [company_map[code] for code in correlation_matrix_stocks.index]\n",
    "\n",
    "# define a linkage matrix to draw the dendogram with, use the above dissimilarity matrix\n",
    "# use average linkage\n",
    "average_linkage_matrix = linkage(dissimilarity_matrix, method='average')\n",
    "\n",
    "# visualize the dendogram using dendogram object\n",
    "\n",
    "# define the size of the plot \n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Assuming `stock_names` is a list of 30 stock names corresponding to the matrix rows/columns\n",
    "# use orientation of right for a horizontal dendogram\n",
    "\n",
    "dendrogram(\n",
    "    average_linkage_matrix,\n",
    "    orientation='right',        \n",
    "    labels=company_names,  # insert the appropriate labels \n",
    "    leaf_font_size=11,          # change the leaf nodes font size for better readability\n",
    ")\n",
    "\n",
    "# insert the appropriate title\n",
    "plt.title('Dendrogram using Average Linkage ')\n",
    "# insert the appropriate x label\n",
    "plt.xlabel('Distance/Dissimilarity')\n",
    "# insert the appropriate y label\n",
    "plt.ylabel('Stocks')\n",
    "plt.tight_layout()\n",
    "# display the plot \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the neccessary library \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# use a pca object with 2 principal components \n",
    "pca_object_2 = PCA(n_components=2)\n",
    "# get the pca score by projecting the data into two principal components \n",
    "pca_scores = pca_object_2.fit_transform(correlation_matrix_stocks)\n",
    "\n",
    "# get the weightings/loadings of each principal components \n",
    "# define the first principal component loadings \n",
    "pc1_loadings = pca_object_2.components_[0] \n",
    "# define the second principal component loadings/ weightings \n",
    "pc2_loadings = pca_object_2.components_[1]\n",
    "\n",
    "# instantiate a kmeans object using 3 clusters \n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "# get the clusters using the kmeans object \n",
    "clusters = kmeans.fit_predict(pca_scores)\n",
    "\n",
    "# create the dataframe for a better visualization \n",
    "\n",
    "clusteredStocks = pd.DataFrame({\n",
    "    # get the stocks to be used as labels \n",
    "    'All stocks': correlation_matrix_stocks.index,\n",
    "    # define the first principal component score\n",
    "    'Principal_comp1': pca_scores[:, 0],  \n",
    "    # define the second principal component score\n",
    "    'Principal_comp2': pca_scores[:, 1],  \n",
    "    'Cluster': clusters\n",
    "})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Use different colors for each cluster to identify d\n",
    "plt.scatter(clusteredStocks['Principal_comp1'], clusteredStocks['Principal_comp2'], c=clusteredStocks['Cluster'], \n",
    "            cmap='plasma', s=100)\n",
    "\n",
    "# Add a text label identifying the stocks \n",
    "for i, stock in enumerate(clusteredStocks['All stocks']):\n",
    "    plt.text(clusteredStocks['Principal_comp1'][i], clusteredStocks['Principal_comp2'][i], stock, fontsize=9)\n",
    "# insert the appropriate title\n",
    "plt.title('K means clustering making use of Principal Components ')\n",
    "# insert the x label\n",
    "plt.xlabel('First Principal Component')\n",
    "# insert the y label \n",
    "plt.ylabel('Second Principal Component')\n",
    "# show a color for the different clusters \n",
    "plt.colorbar(label='Cluster')\n",
    "# display the plot \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# show the clustered groups\n",
    "\n",
    "for c_id in clusteredStocks['Cluster'].unique():\n",
    "    cluster_members = clusteredStocks[clusteredStocks['Cluster'] == c_id]['All stocks']\n",
    "    cluster_members_names= [company_map[com_id] for com_id in cluster_members]\n",
    "    print(f\"Cluster {c_id}: {', '.join(cluster_members_names)}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
